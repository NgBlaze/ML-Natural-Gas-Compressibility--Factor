{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10d3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF, ConstantKernel as C\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Load your data \n",
    "data = pd.read_csv('df_for_models.csv')\n",
    "\n",
    "# Select relevant features and target variable\n",
    "selected_features = ['Pseudoreduced Temperature', 'Pseudoreduced Pressure']\n",
    "target_variable = 'z'\n",
    "X = data[selected_features]\n",
    "y = data[target_variable]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameters grid\n",
    "param_grid = {\n",
    "    \"kernel\": [C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2)) + WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e+1))],\n",
    "    \"n_restarts_optimizer\": [10, 20],\n",
    "    \"alpha\": [1e-10, 1e-5, 1e-3],\n",
    "}\n",
    "\n",
    "# Initialize GPR with default parameters\n",
    "gpr = GaussianProcessRegressor(random_state=42)\n",
    "\n",
    "print(\"Starting grid search for hyperparameters...\")\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(gpr, param_grid=param_grid, cv=5, n_jobs=-1, scoring='r2', verbose=1)\n",
    "\n",
    "# Fit the model to the training data with grid search for hyperparameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Grid search completed.\")\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set and training set\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "\n",
    "# Calculate R-squared for evaluation\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"R-squared (Train): {r2_train:.6f}\")\n",
    "print(f\"R-squared (Test): {r2_test:.6f}\")\n",
    "\n",
    "# Plotting predicted vs measured with different colors\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot for y_train vs y_train_pred with different colors for train data\n",
    "predicted_colors_train = ['tomato' if pred >= actual else 'tomato' for pred, actual in zip(y_pred_train, y_train)]\n",
    "pred_actual_scatter_train = ax.scatter(y_train, y_pred_train, c=predicted_colors_train, marker=\".\", s=40, label='Train Data')\n",
    "\n",
    "# Scatter plot for predicted vs measured with different colors for test data\n",
    "predicted_colors_test = ['blue' if pred >= actual else 'blue' for pred, actual in zip(y_pred_test, y_test)]\n",
    "pred_actual_scatter_test = ax.scatter(y_test, y_pred_test, c=predicted_colors_test, marker=\".\", s=40)\n",
    "\n",
    "# Plot line of equality with grey color and dashed style\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='grey', linestyle='--', lw=1, label='Line of Equality')\n",
    "\n",
    "# Legends for distinguishing predicted and actual markers for test and train data\n",
    "overprediction_patch = mpatches.Patch(color='blue', label='Test Data')\n",
    "underprediction_train_patch = mpatches.Patch(color='tomato', label='Train Data')\n",
    "\n",
    "# Annotation for R-squared values on the plot at the bottom right\n",
    "ax.text(0.95, 0.05, f'R\\u00b2 (Train) = {r2_train:.6f}', transform=ax.transAxes,\n",
    "        fontsize=10, color='tomato', ha='right', va='bottom')\n",
    "ax.text(0.95, 0.1, f'R\\u00b2 (Test) = {r2_test:.6f}', transform=ax.transAxes,\n",
    "        fontsize=10, color='blue', ha='right', va='bottom')\n",
    "\n",
    "# Create the legend\n",
    "legend_elements = [\n",
    "    overprediction_patch,\n",
    "    underprediction_train_patch,\n",
    "]\n",
    "\n",
    "# Set plot title and labels\n",
    "ax.set_title('Predicted vs Measured')\n",
    "ax.set_xlabel('Measured Values')\n",
    "ax.set_ylabel('Predicted Values')\n",
    "\n",
    "# Create the legend\n",
    "plt.legend(handles=legend_elements)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8bc984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40cb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for training data\n",
    "train_results = pd.DataFrame({\n",
    "    'Data Type': 'Train',\n",
    "    'Actual z': y_train,\n",
    "    'Predicted z': y_pred_train\n",
    "})\n",
    "\n",
    "# Create DataFrame for testing data\n",
    "test_results = pd.DataFrame({\n",
    "    'Data Type': 'Test',\n",
    "    'Actual z': y_test,\n",
    "    'Predicted z': y_pred_test\n",
    "})\n",
    "\n",
    "# Concatenate the training and testing data\n",
    "model_results = pd.concat([train_results, test_results], ignore_index=True)\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "model_results.to_excel(\" GPR  pseudo data results.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7314a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e7962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Calculate evaluation metrics for test data\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "mape_test = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Calculate evaluation metrics for train data\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mape_train = np.mean(np.abs((y_train - y_pred_train) / y_train)) * 100\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "# Print the evaluation metrics for test data\n",
    "print(\"Evaluation Metrics for Test Data:\")\n",
    "print(f'Mean Absolute Error (MAE): {mae_test:.9f}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE): {mape_test:.9f}%')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_test:.9f}')\n",
    "print(f'R\\u00b2 Value: {r2_test:.9f}')\n",
    "\n",
    "# Print the evaluation metrics for train data\n",
    "print(\"\\nEvaluation Metrics for Train Data:\")\n",
    "print(f'Mean Absolute Error (MAE): {mae_train:.9f}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE): {mape_train:.9f}%')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_train:.9f}')\n",
    "print(f'R\\u00b2 Value: {r2_train:.9f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636d285c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate residuals for the training data\n",
    "residuals_train = ((y_pred_train - y_train) / y_train) * 100\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate residuals for the testing data\n",
    "residuals_test = ((y_pred_test - y_test) / y_test) * 100\n",
    "\n",
    "# Separate residuals into overprediction and underprediction categories for the training data\n",
    "over_prediction_train = y_pred_train[residuals_train > 0]\n",
    "under_prediction_train = y_pred_train[residuals_train <= 0]\n",
    "\n",
    "# Separate residuals into overprediction and underprediction categories for the testing data\n",
    "over_prediction_test = y_pred_test[residuals_test > 0]\n",
    "under_prediction_test = y_pred_test[residuals_test <= 0]\n",
    "\n",
    "# Plotting residuals for both training and testing data\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting overpredictions in green and underpredictions in red for the training data\n",
    "plt.scatter(over_prediction_train, residuals_train[residuals_train > 0], c='tomato', marker='o', edgecolor='black', alpha=0.7, label='Train Relative Percentage Errors')\n",
    "plt.scatter(under_prediction_train, residuals_train[residuals_train <= 0], c='tomato', marker='o', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Plotting overpredictions in blue and underpredictions in orange for the testing data\n",
    "plt.scatter(over_prediction_test, residuals_test[residuals_test > 0], c='blue', marker='o', edgecolor='black', alpha=0.7, label='Test Relative Percentage Errors')\n",
    "plt.scatter(under_prediction_test, residuals_test[residuals_test <= 0], c='blue', marker='o', edgecolor='black', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Percentage Relative Errors')\n",
    "plt.title('Percentage Relative Errors of GPR Model')\n",
    "\n",
    "# Adding a horizontal line at y=0\n",
    "plt.axhline(y=0, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "# Show legends\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd1370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8869fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
